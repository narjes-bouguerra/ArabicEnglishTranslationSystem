{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!perl /kaggle/input/cleaning/clean-corpus-n.perl -max-word-length 50 /kaggle/input/newdataset-en-to-ar/train ar en train.clean 0 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l train.clean.en train.clean.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kpu/preprocess.git\n",
    "%cd preprocess\n",
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ..\n",
    "!make -j4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!preprocess/build/bin/simple_cleaning -p train.clean.ar train.clean.en newdata/train.clean.pp.ar newdata/train.clean.pp.en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!preprocess/build/bin/simple_cleaning -p test.clean.ar test.clean.en newdata/test.clean.pp.ar newdata/test.clean.pp.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!preprocess/build/bin/dedupe -p newdata/test.clean.pp.ar newdata/test.clean.pp.en newdata/test.clean.pp.dedup.ar newdata/test.clean.pp.dedup.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacremoses normalize < newdata/valid.clean.pp.dedup.ar > normalize/valid.norm.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacremoses normalize < newdata/valid.clean.pp.dedup.en > normalize/valid.norm.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat normalize/train.norm.ar normalize/train.norm.en > normalize/train.norm.ar-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Path to the input text file\n",
    "input_file = 'normalize/train.norm.ar-en'\n",
    "\n",
    "# Model prefix for saving the trained model\n",
    "model_prefix = 'ar-en.32kspm'\n",
    "\n",
    "# Vocabulary size for the SentencePiece model\n",
    "vocab_size = 32000\n",
    "\n",
    "# Train the SentencePiece model\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=input_file,\n",
    "    model_prefix=model_prefix,\n",
    "    vocab_size=vocab_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import Field, BucketIterator,TabularDataset\n",
    "\n",
    "sys.path.append('/kaggle/input/modelfile')\n",
    "\n",
    "from model import Encoder, Decoder, Seq2Seq\n",
    "import random\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('ar-en.32kspm.model')\n",
    "\n",
    "def tokenize_ar(x):\n",
    "    x = str(x).lower()\n",
    "    return sp.EncodeAsPieces(x)\n",
    "\n",
    "def tokenize_en(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.translate({ord(c): None for c in '!.?,'})\n",
    "    return x.split()\n",
    "\n",
    "\n",
    "SRC = Field(tokenize=tokenize_ar, init_token='<sos>', eos_token='<eos>')\n",
    "TRG = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "dataset = TabularDataset(path='dataset.csv', format='csv', fields=[('ar', SRC), ('en', TRG)], skip_header=True)\n",
    "train_dt, valid_dt, test_dt = dataset.split(split_ratio=[0.7, 0.1, 0.2], random_state=random.getstate())\n",
    "\n",
    "SRC.build_vocab(train_dt, min_freq=2)\n",
    "TRG.build_vocab(train_dt, min_freq=2)\n",
    "\n",
    "bsize = 32\n",
    "gpu = True\n",
    "device = torch.device('cuda' if gpu and torch.cuda.is_available() else 'cpu')\n",
    "train_it, valid_it, test_it = BucketIterator.splits((train_dt, valid_dt, test_dt), batch_size=bsize, sort_key=lambda x: len(x.ar), sort_within_batch=False, device=device)\n",
    "\n",
    "'''\n",
    "for b in train_it:\n",
    "    print (b.ar, b.en)\n",
    "    sys.exit()\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(train_it.dataset)\n",
    "batch_size = train_it.batch_size\n",
    "num_iterations = num_examples // batch_size\n",
    "print(num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='translationmodel_lstm2')\n",
    "def train(model, train_it, optimizer, criterion, clip, accumulation_steps):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    accumulation_steps_counter = 0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(train_it)):\n",
    "        src = batch.ar\n",
    "        trg = batch.en\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        accumulation_steps_counter += 1\n",
    "        if accumulation_steps_counter == accumulation_steps:\n",
    "            optimizer.step()\n",
    "            accumulation_steps_counter = 0\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        wandb.log({'iteration': i + 1, 'loss': loss.item()})\n",
    "\n",
    "    if accumulation_steps_counter != 0:\n",
    "        optimizer.step()  # Perform the remaining update\n",
    "\n",
    "    return epoch_loss / len(train_it)\n",
    "\n",
    "def evaluate(model, data_it, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in tqdm(enumerate(data_it)):\n",
    "        src = batch.ar\n",
    "        trg = batch.en\n",
    "        output = model(src, trg, 0)\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/ len(data_it)\n",
    "\n",
    "input_dim = len(SRC.vocab)\n",
    "out_dim = len(TRG.vocab)\n",
    "enc_emb_dim = 128\n",
    "dec_emb_dim = 128\n",
    "hidden_dim = 256\n",
    "nlayers = 2\n",
    "enc_dropout = 0.3\n",
    "dec_dropout = 0.3\n",
    "enc = Encoder(input_dim, enc_emb_dim, hidden_dim, nlayers, enc_dropout)\n",
    "dec = Decoder(out_dim, dec_emb_dim, hidden_dim, nlayers, dec_dropout)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "pad_idx = TRG.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "epoch = 10\n",
    "clip = 1\n",
    "savedir = 'models'\n",
    "model_save_path = os.path.join(savedir, 's2smodel.pt')\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{savedir}'):\n",
    "    os.makedirs(f'{savedir}')\n",
    "for ep in range(epoch):\n",
    "    train_loss = train(model, train_it, optimizer, criterion, clip, accumulation_steps=4)\n",
    "    valid_loss = evaluate(model, valid_it, criterion)\n",
    "    wandb.log({'epoch': ep+1, 'train_loss': train_loss, 'valid_loss': valid_loss})\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "    print (f'epoch: {ep+1:03} | train loss: {train_loss: .3f} | train_ppl: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f} |')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel import DataParallel\n",
    "wandb.init(project='translationmodel_lstm')\n",
    "def train(model, train_it, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in tqdm(enumerate(train_it)):\n",
    "        src = batch.ar\n",
    "        trg = batch.en\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        wandb.log({'iteration': i+1, 'loss': loss.item()})\n",
    "    return epoch_loss/ len(train_it)\n",
    "\n",
    "def evaluate(model, data_it, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in tqdm(enumerate(data_it)):\n",
    "        src = batch.ar\n",
    "        trg = batch.en\n",
    "        output = model(src, trg, 0)\n",
    "        loss = criterion(output[1:].view(-1, output.shape[-1]), trg[1:].view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/ len(data_it)\n",
    "\n",
    "input_dim = len(SRC.vocab)\n",
    "out_dim = len(TRG.vocab)\n",
    "enc_emb_dim = 128\n",
    "dec_emb_dim = 128\n",
    "hidden_dim = 256\n",
    "nlayers = 2\n",
    "enc_dropout = 0.3\n",
    "dec_dropout = 0.3\n",
    "enc = Encoder(input_dim, enc_emb_dim, hidden_dim, nlayers, enc_dropout)\n",
    "dec = Decoder(out_dim, dec_emb_dim, hidden_dim, nlayers, dec_dropout)\n",
    "model = Seq2Seq(enc, dec, device)\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "pad_idx = TRG.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "epoch = 10\n",
    "clip = 1\n",
    "savedir = 'models'\n",
    "model_save_path = os.path.join(savedir, 's2smodel.pt')\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{savedir}'):\n",
    "    os.makedirs(f'{savedir}')\n",
    "for ep in range(epoch):\n",
    "    train_loss = train(model, train_it, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, valid_it, criterion)\n",
    "    wandb.log({'epoch': ep+1, 'train_loss': train_loss, 'valid_loss': valid_loss})\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "    print (f'epoch: {ep+1:03} | train loss: {train_loss: .3f} | train_ppl: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f} |')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/pytorch/fairseq\n",
    "%cd fairseq\n",
    "! pip install --editable ./\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "SRCS = [\"ar\"]  # Replace with your desired source languages\n",
    "TGT = \"en\"  # Replace with your target language\n",
    "\n",
    "SPM_ENCODE = \"fairseq/scripts/spm_encode.py\"  # Replace with the path to your sentencepiece_encode.py script\n",
    "DATA = \"normalize\"  # Replace with the path to your data directory\n",
    "TRAIN_MINLEN = 1  # Replace with your desired minimum length\n",
    "TRAIN_MAXLEN = 1000  # Replace with your desired maximum length\n",
    "\n",
    "# Encoding train and valid data\n",
    "print(\"Encoding train/valid with learned BPE...\")\n",
    "for SRC in SRCS:\n",
    "    for LANG in [SRC, TGT]:\n",
    "        train_input = f\"{DATA}/train.norm.{LANG}\"\n",
    "        train_output = f\"{DATA}/train.bpe.{SRC}-{TGT}.{LANG}\"\n",
    "        valid_input = f\"{DATA}/valid.norm.{LANG}\"\n",
    "        valid_output = f\"{DATA}/valid.bpe.{SRC}-{TGT}.{LANG}\"\n",
    "        \n",
    "        # Encoding train data\n",
    "        subprocess.run([\n",
    "            \"python\", SPM_ENCODE,\n",
    "            \"--model\", f\"ar-en.32kspm.model\",\n",
    "            \"--output_format=piece\",\n",
    "            \"--inputs\", train_input,\n",
    "            \"--outputs\", train_output,\n",
    "            \"--min-len\", str(TRAIN_MINLEN),\n",
    "            \"--max-len\", str(TRAIN_MAXLEN)\n",
    "        ])\n",
    "        \n",
    "        # Encoding valid data\n",
    "        subprocess.run([\n",
    "            \"python\", SPM_ENCODE,\n",
    "            \"--model\", f\"ar-en.32kspm.model\",\n",
    "            \"--output_format=piece\",\n",
    "            \"--inputs\", valid_input,\n",
    "            \"--outputs\", valid_output\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-preprocess \\\n",
    " --source-lang ar \\\n",
    " --target-lang en \\\n",
    " --trainpref normalize/train.bpe.ar-en\\\n",
    " --validpref normalize/valid.bpe.ar-en \\\n",
    " --joined-dictionary \\\n",
    " --destdir ar-en-lstm \\\n",
    " --workers 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-preprocess \\\n",
    " --source-lang ar \\\n",
    " --target-lang en \\\n",
    " --trainpref normalize/train.bpe.ar-en\\\n",
    " --validpref normalize/valid.bpe.ar-en \\\n",
    " --destdir en-ar-lstm \\\n",
    " --workers 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-train en-ar-lstm \\\n",
    "  --arch lstm \\\n",
    "  --encoder-layers 2 \\\n",
    "  --decoder-layers 2 \\\n",
    "  --dropout 0.3 \\\n",
    "  --optimizer adam \\\n",
    "  --lr 5e-4 \\\n",
    "  --criterion label_smoothed_cross_entropy \\\n",
    "  --encoder-bidirectional \\\n",
    "  --label-smoothing 0.1 \\\n",
    "  --save-dir checkpoints/lstm \\\n",
    "  --save-interval-updates 30000 \\\n",
    "  --max-update 100000 \\\n",
    "  --batch-size 100 \\\n",
    "  --update-freq 1 \\\n",
    "  --wandb-project \"multilangual lstm en to ar\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-train en-ar-lstm \\\n",
    "  --arch transformer \\\n",
    "  --dropout 0.1 \\\n",
    "  --max-tokens 2000 \\\n",
    "  --attention-dropout 0.1 \\\n",
    "  --activation-dropout 0.1 \\\n",
    "  --encoder-embed-dim 256 \\\n",
    "  --encoder-ffn-embed-dim 512 \\\n",
    "  --encoder-layers 3 \\\n",
    "  --encoder-attention-heads 8 \\\n",
    "  --encoder-learned-pos \\\n",
    "  --decoder-embed-dim 256 \\\n",
    "  --decoder-ffn-embed-dim 512 \\\n",
    "  --decoder-layers 3 \\\n",
    "  --decoder-attention-heads 8 \\\n",
    "  --decoder-learned-pos \\\n",
    "  --max-epoch 10 \\\n",
    "  --optimizer adam \\\n",
    "  --adam-betas \"[0.9, 0.98]\" \\\n",
    "  --lr 5e-4 \\\n",
    "  --batch-size 128 \\\n",
    "  --seed 1 \\\n",
    "  --save-interval 2 \\\n",
    "  --memory-efficient-fp16 \\\n",
    "  --update-freq 1 \\\n",
    "  --save-dir checkpoints \\\n",
    "  --wandb-project \"Translation-senp_transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from fairseq.models.lstm import LSTMModel\n",
    "\n",
    "# Load the SentencePiece model\n",
    "sp_model_path = \"ar-en.32kspm.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(sp_model_path)\n",
    "\n",
    "# Load the Fairseq trained model\n",
    "model_path = \"checkpoints/lstm\"\n",
    "model = LSTMModel.from_pretrained(\n",
    "    model_path,\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=\"en-ar-lstm\",\n",
    "    source_lang=\"ar\",  # Specify the source language code\n",
    "    target_lang=\"en\",  # Specify the target language code\n",
    ")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Translate interactively\n",
    "while True:\n",
    "    # Take user input\n",
    "    input_sentence = input(\"Enter a sentence in English (or 'q' to quit): \")\n",
    "\n",
    "    if input_sentence.lower() == \"q\":\n",
    "        break\n",
    "\n",
    "    # Tokenize the input sentence using SentencePiece\n",
    "    tokens = sp.encode_as_ids(input_sentence)\n",
    "\n",
    "    # Convert the tokens to PyTorch tensor\n",
    "    input_tensor = torch.LongTensor(tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Generate translation using the model\n",
    "    with torch.no_grad():\n",
    "        translation = model.generate(input_tensor, beam=5)\n",
    "\n",
    "    # Get the translated sentence without special tokens\n",
    "    translation_sentence = sp.decode_ids(translation[0][0][\"tokens\"].tolist())\n",
    "\n",
    "    print(\"Translated Sentence:\", translation_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from fairseq.models.lstm import LSTMModel\n",
    "\n",
    "# Load the SentencePiece model\n",
    "sp_model_path = \"ar-en.32kspm.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(sp_model_path)\n",
    "\n",
    "# Load the Fairseq trained model\n",
    "model_path = \"checkpoints/lstm\"\n",
    "model = LSTMModel.from_pretrained(\n",
    "    model_path,\n",
    "    checkpoint_file=\"checkpoint_best.pt\",\n",
    "    data_name_or_path=\"en-ar-lstm\",\n",
    "    source_lang=\"ar\",  # Specify the source language code\n",
    "    target_lang=\"en\",  # Specify the target language code\n",
    ")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Translate interactively\n",
    "while True:\n",
    "    # Take user input\n",
    "    input_sentence = input(\"Enter a sentence in English (or 'q' to quit): \")\n",
    "\n",
    "    if input_sentence.lower() == \"q\":\n",
    "        break\n",
    "\n",
    "    # Encode the input sentence using SentencePiece\n",
    "    encoded_sentence = sp.encode_as_pieces(input_sentence)\n",
    "\n",
    "    # Remove BPE encoding\n",
    "    encoded_sentence = [piece.replace(\"@@ \", \"\") for piece in encoded_sentence]\n",
    "\n",
    "    # Convert the tokens to PyTorch tensor\n",
    "    input_tensor = torch.LongTensor([sp.piece_to_id(piece) for piece in encoded_sentence]).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Generate translation using the model\n",
    "    with torch.no_grad():\n",
    "        translation = model.generate(input_tensor, beam=1)\n",
    "\n",
    "    # Get the translated sentence without special tokens\n",
    "    translation_ids = translation[0][0][\"tokens\"].tolist()\n",
    "    translation_sentence = sp.decode_ids(translation_ids)\n",
    "\n",
    "    print(\"Translated Sentence:\", translation_sentence)\n",
    "    print(input_tensor)\n",
    "    print(translation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 01:46:38 | INFO | fairseq.file_utils | loading archive file transformer\n",
      "2023-06-25 01:46:38 | INFO | fairseq.file_utils | loading archive file en-ar-lstm\n",
      "2023-06-25 01:46:39 | INFO | fairseq.tasks.translation | [ar] dictionary: 32488 types\n",
      "2023-06-25 01:46:39 | INFO | fairseq.tasks.translation | [en] dictionary: 19704 types\n",
      "2023-06-25 01:46:39 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'Translation-senp_transformer', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:59849', 'distributed_port': 59849, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2000, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2000, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project='Translation-senp_transformer', azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe='sentencepiece', optimizer='adam', lr_scheduler='fixed', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=2000, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=2000, batch_size_valid=128, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer', max_epoch=10, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=2, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='en-ar-lstm', source_lang='ar', target_lang='en', load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, adam_betas='[0.9, 0.98]', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, encoder_embed_dim=256, encoder_ffn_embed_dim=512, encoder_layers=3, encoder_attention_heads=8, encoder_learned_pos=True, decoder_embed_dim=256, decoder_ffn_embed_dim=512, decoder_layers=3, decoder_attention_heads=8, decoder_learned_pos=True, no_seed_provided=False, encoder_embed_path=None, encoder_normalize_before=False, decoder_embed_path=None, decoder_normalize_before=False, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=False, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer', max_source_positions=1024, max_target_positions=1024, min_params_to_wrap=100000000, sentencepiece_vocab='ar-en.32kspm.vocab', spm_model_path='ar-en.32kspm.model', sentencepiece_model='ar-en.32kspm.model'), 'task': {'_name': 'translation', 'data': 'en-ar-lstm', 'source_lang': 'ar', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '[0.9, 0.98]', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'ar-en.32kspm.model', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  sameh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Sameh Sameh\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  سامح\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Samhah\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  نرجس\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Virgins Nession\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  نرجس\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Virgins Nession\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  مروان\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Marwan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  سماح\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Samar Smam\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  لا\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: No No No\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  لا لا\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: No No No No No\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  لا ياض\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: Do not persuade\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  لا ياصديقي\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: No friend or friendy\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  لا noel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: No noel\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence in English (or 'q' to quit):  ذهبت مع jonathan إلى السوق.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: I went with jonathan to the market.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Translate interactively\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Take user input\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     input_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter a sentence in English (or \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to quit): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_sentence\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.data.encoders import register_bpe\n",
    "\n",
    "class SentencePieceBPE(object):\n",
    "    def __init__(self, args):\n",
    "        import sentencepiece as spm\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(args.spm_model_path)\n",
    "\n",
    "    def encode(self, x: str) -> str:\n",
    "        return self.sp.EncodeAsPieces(x)\n",
    "\n",
    "    def decode(self, x: str) -> str:\n",
    "        return self.sp.DecodePieces(x)\n",
    "\n",
    "\n",
    "# Register SentencePieceBPE as BPE for Fairseq\n",
    "register_bpe(\"sentencepiece\", SentencePieceBPE)\n",
    "\n",
    "# Load the Fairseq trained model\n",
    "model_path = \"transformer\"\n",
    "model = TransformerModel.from_pretrained(\n",
    "    model_path,\n",
    "    checkpoint_file=\"snp-transf.pt\",\n",
    "    data_name_or_path=\"en-ar-lstm\",\n",
    "    source_lang=\"ar\",  # Specify the source language code\n",
    "    target_lang=\"en\",  # Specify the target language code\n",
    "    bpe=\"sentencepiece\",  # Use SentencePiece BPE\n",
    "    sentencepiece_vocab=\"ar-en.32kspm.vocab\",  # Path to SentencePiece vocabulary\n",
    "    spm_model_path=\"ar-en.32kspm.model\",  # Path to SentencePiece model\n",
    "    sentencepiece_model=\"ar-en.32kspm.model\",  # Path to SentencePiece model\n",
    ")\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Translate interactively\n",
    "while True:\n",
    "    # Take user input\n",
    "    input_sentence = input(\"Enter a sentence in English (or 'q' to quit): \")\n",
    "\n",
    "    if input_sentence.lower() == \"q\":\n",
    "        break\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = model.encode(input_sentence)\n",
    "\n",
    "    # Convert the tokens to PyTorch tensor\n",
    "    input_tensor = torch.LongTensor(tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Generate translation using the model\n",
    "    with torch.no_grad():\n",
    "        translation = model.generate(input_tensor, beam=5)\n",
    "\n",
    "    # Get the translated sentence without special tokens\n",
    "    translation_sentence = model.decode(translation[0][0][\"tokens\"])\n",
    "\n",
    "    print(\"Translated Sentence:\", translation_sentence)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf archive.tar.gz en-ar-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fairseq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
