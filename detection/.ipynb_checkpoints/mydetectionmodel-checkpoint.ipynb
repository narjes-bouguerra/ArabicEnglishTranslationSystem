{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ------------------------------------ 293.3/293.3 kB 754.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from seaborn) (2.0.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in h:\\anaconda\\envs\\ldetection\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QG9d1RPtFDyi"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import codecs\n",
    "import numpy as np\n",
    "import  pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_extraction \n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TwPJghR1FNj0",
    "outputId": "bfb40dbb-c0ad-46f6-e504-a9b2555954ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr john is a very good man</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonjour et bonsoir l'amie</td>\n",
       "      <td>Wrong Input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bon, c'est grave ça</td>\n",
       "      <td>Wrong Input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadly this guy is very deadly</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Text     Language\n",
       "0     Mr john is a very good man      English\n",
       "1      Bonjour et bonsoir l'amie  Wrong Input\n",
       "2            bon, c'est grave ça  Wrong Input\n",
       "3                  unfortunately      English\n",
       "4  sadly this guy is very deadly      English"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('Language Detection2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6vJvxiLFURe",
    "outputId": "d0a1d559-3f3f-4175-a118-f8bcb56774a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
     ]
    }
   ],
   "source": [
    "for char in string.punctuation:\n",
    "    print(char, end=\"\")\n",
    "translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "# créer une liste vide pour stocker les lignes\n",
    "data = []\n",
    "\n",
    "# lire le fichier et ajouter chaque ligne à la liste\n",
    "with open('Language Detection2.csv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # supprimer les nombres commençant par \"r\"\n",
    "        line = re.sub(\"r\\d+\", \"\", line)\n",
    "        line= line.translate(translate_table)\n",
    "        if len(line.strip()) > 0:\n",
    "            data.append(line.strip().lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xk8-WuSnFaMA"
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "    return df[indices_to_keep].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eIsW3ShGFhzj"
   },
   "outputs": [],
   "source": [
    "df = clean_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m1Ns5WN4FlVr"
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,0]\n",
    "y = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yvURMzMcFq0J"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size =.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKz0LwxoFwnW",
    "outputId": "516d7976-4717-4f8a-ace2-35bafb065c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150412,)\n",
      "(37604,)\n",
      "(150412,)\n",
      "(37604,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vnK2DTnvGAGj"
   },
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "IiaO3u0MGGCz",
    "outputId": "fbefbf93-b644-4083-abb4-674432467d46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='char', ngram_range=(1, 3))),\n",
       "                ('scaler', StandardScaler(with_mean=False)),\n",
       "                ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), analyzer='char')\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "model_pipe = Pipeline([('vectorizer', vectorizer), ('scaler', scaler), ('logreg', logreg)])\n",
    "model_pipe.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmO2j2ttSQTk",
    "outputId": "26f6afc0-1495-4180-8471-6c4de37a0e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'English', 'Wrong Input'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T8vZ5a81Ga8A"
   },
   "outputs": [],
   "source": [
    "y_predicted = model_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J9fSLxwYG84M"
   },
   "outputs": [],
   "source": [
    "acc = (metrics.accuracy_score(Y_test , y_predicted ))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vPkKZgPHY5j",
    "outputId": "bfabbe71-511b-44a5-c177-47647e52d492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.51866822678438 %\n"
     ]
    }
   ],
   "source": [
    "print(acc, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNzFEvHNIww2",
    "outputId": "d1d1ca58-eff5-4cd7-e4c0-a394d1c5892a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 5235     0     6]\n",
      " [    0  5070    56]\n",
      " [    6   113 27118]]\n"
     ]
    }
   ],
   "source": [
    "matrix = metrics.confusion_matrix(Y_test, y_predicted)\n",
    "print('Confusion matrix : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tyv-vJa9JYXh"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "lrFile = open('LRModel.pck1' , 'wb')\n",
    "pickle.dump(model_pipe, lrFile)\n",
    "lrFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Qmxtw057KeCc"
   },
   "outputs": [],
   "source": [
    "global lrLangDetectModel\n",
    "lrLangDetectFile = open ('LRModel.pck1' , 'rb')\n",
    "lrLangDetectModel = pickle.load(lrLangDetectFile)\n",
    "lrLangDetectFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nfdm3FEvLlqv"
   },
   "outputs": [],
   "source": [
    "def lang_detect(text):\n",
    "  import numpy as np\n",
    "  import string\n",
    "  import re\n",
    "  import re\n",
    "  import pickle \n",
    "  translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "  global lrLangDetectModel\n",
    "  lrLangDetectFile = open ('LRModel.pck1' , 'rb')\n",
    "  lrLangDetectModel = pickle.load(lrLangDetectFile)\n",
    "  lrLangDetectFile.close()\n",
    "\n",
    "  text = \"\".join(text.split())\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"\\d+\", \"\", text)\n",
    "  text = text.translate(translate_table)\n",
    "  pred = lrLangDetectModel.predict([text])\n",
    "  prob = lrLangDetectModel.predict_proba([text])\n",
    "  return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kuw5qOLRN84v",
    "outputId": "e744224d-03d9-40b7-cec7-ec46005a0e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\" hi how are you doing today ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mCksptG-OLU7",
    "outputId": "9d41b2e7-669a-432b-d3ab-6ee12dfa48cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wrong Input'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"Bonjour , je viens de créér mon propre  modele \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZnrJTZ6pS1nW",
    "outputId": "5f58451b-f456-427e-ac59-9f9e68dfc8e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wrong Input'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"ich liebe dich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kzxUWUVxTTXQ",
    "outputId": "76a3f844-d8c7-485f-9cc6-96648078db5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wrong Input'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"ich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "o4EJ1pLSTB_7",
    "outputId": "bda5b8d3-dfb8-4d62-b9f5-dc4121dab264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"i have a dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "CSBzsEuuTcJI",
    "outputId": "d1d1895d-05c0-4446-f979-3a4f7d90d0b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xoNEmiExTgsA",
    "outputId": "2607c2ef-e62f-41fc-8215-3ded8a78653b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "gXql3nFQOYxE",
    "outputId": "6e36473f-aca2-4bbd-d6a0-7831cfce7e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arabic'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"الحياة\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Df3H3rbFT9uK",
    "outputId": "bde3dfc1-e4db-461e-c3f7-12e90d9641e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arabic'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"ازهر النرجس\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjdsjcxyPAiX",
    "outputId": "97f309dd-7108-4f66-8d30-849b24177970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'English', 'Wrong Input'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"avec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_detect(\"nous sommes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     -------------------------------------- 981.5/981.5 kB 1.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in h:\\anaconda\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=984c013a73e35259f1604ada4f9cdb78b8abd662270e9905f6ed1fefddb7dfc3\n",
      "  Stored in directory: c:\\users\\legen\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
